# de-project-1a

Overview: Apache Airflow ETL pipeline with AWS S3

Steps executed:

- ETL DAG and Tasks creation in Airflow
- Data creation and processing using Python programming and AWS SDK
- Data processing and storage on AWS S3 using S3FileTransformOperator
- Pipeline Orchestrattion in Airflow
- Data validation using AWS CLI

Technology Stack used: Docker, Airflow, Python, AWS SDK , AWS CLI and AWS S3
